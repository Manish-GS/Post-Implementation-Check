{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from copy import copy\n",
    "from typing import Union, Optional\n",
    "\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.styles import Font, PatternFill, Alignment\n",
    "from openpyxl.formatting.rule import Rule\n",
    "from openpyxl.styles.differential import DifferentialStyle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_excel_cell_range(\n",
    "        src_ws: openpyxl.worksheet.worksheet.Worksheet,\n",
    "        min_row: int = None,\n",
    "        max_row: int = None,\n",
    "        min_col: int = None,\n",
    "        max_col: int = None,\n",
    "        tgt_ws: openpyxl.worksheet.worksheet.Worksheet = None,\n",
    "        tgt_min_row: int = 1,\n",
    "        tgt_min_col: int = 1,\n",
    "        with_style: bool = True\n",
    ") -> openpyxl.worksheet.worksheet.Worksheet:\n",
    "    \"\"\"\n",
    "    copies all cells from the source worksheet [src_ws] starting from [min_row] row\n",
    "    and [min_col] column up to [max_row] row and [max_col] column\n",
    "    to target worksheet [tgt_ws] starting from [tgt_min_row] row\n",
    "    and [tgt_min_col] column.\n",
    "\n",
    "    @param src_ws:  source worksheet\n",
    "    @param min_row: smallest row index in the source worksheet (1-based index)\n",
    "    @param max_row: largest row index in the source worksheet (1-based index)\n",
    "    @param min_col: smallest column index in the source worksheet (1-based index)\n",
    "    @param max_col: largest column index in the source worksheet (1-based index)\n",
    "    @param tgt_ws:  target worksheet.\n",
    "                    If None, then the copy will be done to the same (source) worksheet.\n",
    "    @param tgt_min_row: target row index (1-based index)\n",
    "    @param tgt_min_col: target column index (1-based index)\n",
    "    @param with_style:  whether to copy cell style. Default: True\n",
    "\n",
    "    @return: target worksheet object\n",
    "    \"\"\"\n",
    "    if tgt_ws is None:\n",
    "        tgt_ws = src_ws\n",
    "\n",
    "    # https://stackoverflow.com/a/34838233/5741205\n",
    "    for row in src_ws.iter_rows(min_row=min_row, max_row=max_row,\n",
    "                                min_col=min_col, max_col=max_col):\n",
    "        for cell in row:\n",
    "            tgt_cell = tgt_ws.cell(\n",
    "                row=cell.row + tgt_min_row - 1,\n",
    "                column=cell.col_idx + tgt_min_col - 1,\n",
    "                value=cell.value\n",
    "            )\n",
    "            if with_style and cell.has_style:\n",
    "                # tgt_cell._style = copy(cell._style)\n",
    "                tgt_cell.font = copy(cell.font)\n",
    "                tgt_cell.border = copy(cell.border)\n",
    "                tgt_cell.fill = copy(cell.fill)\n",
    "                tgt_cell.number_format = copy(cell.number_format)\n",
    "                tgt_cell.protection = copy(cell.protection)\n",
    "                tgt_cell.alignment = copy(cell.alignment)\n",
    "    return tgt_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_df_to_excel(\n",
    "        filename: Union[str, Path],\n",
    "        df: pd.DataFrame,\n",
    "        sheet_name: str = 'Sheet1',\n",
    "        startrow: Optional[int] = None,\n",
    "        max_col_width: int = 30,\n",
    "        autofilter: bool = False,\n",
    "        fmt_int: str = \"#,##0\",\n",
    "        fmt_float: str = \"#,##0.00\",\n",
    "        fmt_date: str = \"yyyy-mm-dd\",\n",
    "        fmt_datetime: str = \"yyyy-mm-dd hh:mm\",\n",
    "        truncate_sheet: bool = False,\n",
    "        storage_options: Optional[dict] = None,\n",
    "        **to_excel_kwargs\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Append a DataFrame [df] to existing Excel file [filename]\n",
    "    into [sheet_name] Sheet.\n",
    "    If [filename] doesn't exist, then this function will create it.\n",
    "\n",
    "    @param filename: File path or existing ExcelWriter\n",
    "                     (Example: '/path/to/file.xlsx')\n",
    "    @param df: DataFrame to save to workbook\n",
    "    @param sheet_name: Name of sheet which will contain DataFrame.\n",
    "                       (default: 'Sheet1')\n",
    "    @param startrow: upper left cell row to dump data frame.\n",
    "                     Per default (startrow=None) calculate the last row\n",
    "                     in the existing DF and write to the next row...\n",
    "    @param max_col_width: maximum column width in Excel. Default: 40\n",
    "    @param autofilter: boolean - whether add Excel autofilter or not. Default: False\n",
    "    @param fmt_int: Excel format for integer numbers\n",
    "    @param fmt_float: Excel format for float numbers\n",
    "    @param fmt_date: Excel format for dates\n",
    "    @param fmt_datetime: Excel format for datetime's\n",
    "    @param truncate_sheet: truncate (remove and recreate) [sheet_name]\n",
    "                           before writing DataFrame to Excel file\n",
    "    @param storage_options: dict, optional\n",
    "        Extra options that make sense for a particular storage connection, e.g. host, port,\n",
    "        username, password, etc., if using a URL that will be parsed by fsspec, e.g.,\n",
    "        starting “s3://”, “gcs://”.\n",
    "    @param to_excel_kwargs: arguments which will be passed to `DataFrame.to_excel()`\n",
    "                            [can be a dictionary]\n",
    "    @return: None\n",
    "\n",
    "    Usage examples:\n",
    "\n",
    "    >>> append_df_to_excel('/tmp/test.xlsx', df, autofilter=True,\n",
    "                           freeze_panes=(1,0))\n",
    "\n",
    "    >>> append_df_to_excel('/tmp/test.xlsx', df, header=None, index=False)\n",
    "\n",
    "    >>> append_df_to_excel('/tmp/test.xlsx', df, sheet_name='Sheet2',\n",
    "                           index=False)\n",
    "\n",
    "    >>> append_df_to_excel('/tmp/test.xlsx', df, sheet_name='Sheet2',\n",
    "                           index=False, startrow=25)\n",
    "\n",
    "    >>> append_df_to_excel('/tmp/test.xlsx', df, index=False,\n",
    "                           fmt_datetime=\"dd.mm.yyyy hh:mm\")\n",
    "\n",
    "    (c) [MaxU](https://stackoverflow.com/users/5741205/maxu?tab=profile)\n",
    "    \"\"\"\n",
    "    def set_column_format(ws, column_letter, fmt):\n",
    "        for cell in ws[column_letter]:\n",
    "            cell.number_format = fmt\n",
    "    filename = Path(filename)\n",
    "    file_exists = filename.is_file()\n",
    "    # process parameters\n",
    "    # calculate first column number\n",
    "    # if the DF will be written using `index=True`, then `first_col = 2`, else `first_col = 1`\n",
    "    first_col = int(to_excel_kwargs.get(\"index\", True)) + 1\n",
    "    # ignore [engine] parameter if it was passed\n",
    "    if 'engine' in to_excel_kwargs:\n",
    "        to_excel_kwargs.pop('engine')\n",
    "    # save content of existing sheets\n",
    "    if file_exists:\n",
    "        wb = load_workbook(filename)\n",
    "        sheet_names = wb.sheetnames\n",
    "        sheet_exists = sheet_name in sheet_names\n",
    "        sheets = {ws.title: ws for ws in wb.worksheets}\n",
    "\n",
    "    with pd.ExcelWriter(\n",
    "        filename.with_suffix(\".xlsx\"),\n",
    "        engine=\"openpyxl\",\n",
    "        mode=\"a\" if file_exists else \"w\",\n",
    "        if_sheet_exists=\"new\" if file_exists else None,\n",
    "        date_format=fmt_date,\n",
    "        datetime_format=fmt_datetime,\n",
    "        storage_options=storage_options\n",
    "    ) as writer:\n",
    "        if file_exists:\n",
    "            # try to open an existing workbook\n",
    "            writer.book = wb\n",
    "            # get the last row in the existing Excel sheet\n",
    "            # if it was not specified explicitly\n",
    "            if startrow is None and sheet_name in writer.book.sheetnames:\n",
    "                startrow = writer.book[sheet_name].max_row\n",
    "            # truncate sheet\n",
    "            if truncate_sheet and sheet_name in writer.book.sheetnames:\n",
    "                # index of [sheet_name] sheet\n",
    "                idx = writer.book.sheetnames.index(sheet_name)\n",
    "                # remove [sheet_name]\n",
    "                writer.book.remove(writer.book.worksheets[idx])\n",
    "                # create an empty sheet [sheet_name] using old index\n",
    "                writer.book.create_sheet(sheet_name, idx)\n",
    "            # copy existing sheets\n",
    "            writer.sheets = sheets\n",
    "        else:\n",
    "            # file doesn't exist, we are creating a new one\n",
    "            startrow = 0\n",
    "\n",
    "        # write out the DataFrame to an ExcelWriter\n",
    "        df.to_excel(writer, sheet_name=sheet_name, **to_excel_kwargs)\n",
    "        worksheet = writer.sheets[sheet_name]\n",
    "\n",
    "        if autofilter:\n",
    "            worksheet.auto_filter.ref = worksheet.dimensions\n",
    "\n",
    "        for xl_col_no, dtyp in enumerate(df.dtypes, first_col):\n",
    "            col_no = xl_col_no - first_col\n",
    "            width = max(df.iloc[:, col_no].astype(str).str.len().max(),\n",
    "                        len(df.columns[col_no]) + 6)\n",
    "            width = min(max_col_width, width)\n",
    "            column_letter = get_column_letter(xl_col_no)\n",
    "            worksheet.column_dimensions[column_letter].width = width\n",
    "            if np.issubdtype(dtyp, np.integer):\n",
    "                set_column_format(worksheet, column_letter, fmt_int)\n",
    "            if np.issubdtype(dtyp, np.floating):\n",
    "                set_column_format(worksheet, column_letter, fmt_float)\n",
    "\n",
    "    if file_exists and sheet_exists:\n",
    "        # move (append) rows from new worksheet to the `sheet_name` worksheet\n",
    "        wb = load_workbook(filename)\n",
    "        # retrieve generated worksheet name\n",
    "        new_sheet_name = set(wb.sheetnames) - set(sheet_names)\n",
    "        if new_sheet_name:\n",
    "            new_sheet_name = list(new_sheet_name)[0]\n",
    "        # copy rows written by `df.to_excel(...)` to\n",
    "        copy_excel_cell_range(\n",
    "            src_ws=wb[new_sheet_name],\n",
    "            tgt_ws=wb[sheet_name],\n",
    "            tgt_min_row=startrow + 1,\n",
    "            with_style=True\n",
    "        )\n",
    "        # remove new (generated by Pandas) worksheet\n",
    "        del wb[new_sheet_name]\n",
    "        wb.save(filename)\n",
    "        wb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data_into_db(db_name, cur):\n",
    "    # Replaces any spaces, &, - characters into underscore\n",
    "    TABLENAME_CLEANING_CHARACTERS = [(\" \", \"_\"),(\"&\", \"_\"),(\"-\", \"_\")]\n",
    "    \n",
    "       \n",
    "    before_file = open(COMPARISON_FILE_PATH + \"/\" + db_name + BEFORE_IMPLMENT_KEYWORD + COMPARISON_FILE_EXTENSION, \"r\")\n",
    "    after_file = open(COMPARISON_FILE_PATH + \"/\" + db_name + AFTER_IMPLMENT_KEYWORD + COMPARISON_FILE_EXTENSION, \"r\")\n",
    "    before_db_data = before_file.read().split(\"\\n\\n\")\n",
    "    after_db_data = after_file.read().split(\"\\n\\n\")\n",
    "    \n",
    "    \n",
    "    for index, table in enumerate(before_db_data + after_db_data):\n",
    "        \n",
    "        if index < len(before_db_data):\n",
    "            table_suffix = BEFORE_IMPLMENT_KEYWORD\n",
    "        else:\n",
    "            table_suffix = AFTER_IMPLMENT_KEYWORD\n",
    "\n",
    "        # Get the data of individual tables\n",
    "        table_info = table.split(\"\\n\")\n",
    "        \n",
    "        if table_info != '' and len(table_info) > 1:\n",
    "            \n",
    "            # Cleaning and storing the table name\n",
    "            table_name = table_info[0][len(\"*** \") : -len(\" ***\")]\n",
    "            table_name = table_name + \"_\" + table_suffix\n",
    "            for clean_char in TABLENAME_CLEANING_CHARACTERS:\n",
    "                table_name = table_name.replace(clean_char[0], clean_char[1])\n",
    "            \n",
    "            # Cleaning and storing the table columns\n",
    "            table_columns = list()\n",
    "            for column in table_info[1].split(\"\\t\"):\n",
    "                table_columns.append(column.replace(\".\", \"_\"))\n",
    "            table_columns = tuple(table_columns)\n",
    "            \n",
    "            # Creating tables and execution\n",
    "            table_creation_query = 'CREATE TABLE {table_name} {table_columns}'\n",
    "            table_creation_query = table_creation_query.format(table_name = table_name, table_columns = table_columns)\n",
    "            try:\n",
    "                cur.execute(table_creation_query)\n",
    "            except sqlite3.OperationalError:\n",
    "                pass\n",
    "            \n",
    "            for data in table_info[2:]:\n",
    "                \n",
    "                # Creating table data and execution\n",
    "                row_data = tuple(data.split(\"\\t\"))\n",
    "                table_data_insertion_query = 'INSERT INTO {table_name} VALUES {table_data}'\n",
    "                table_data_insertion_query = table_data_insertion_query.format(table_name = table_name, table_data = row_data)\n",
    "                cur.execute(table_data_insertion_query)\n",
    "            \n",
    "            con.commit()\n",
    "            \n",
    "    before_file.close()\n",
    "    after_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_result_df(con, table_name):\n",
    "    before_table = table_name + \"_\" + BEFORE_IMPLMENT_KEYWORD\n",
    "    after_table = table_name + \"_\" + AFTER_IMPLMENT_KEYWORD\n",
    "    \n",
    "    # Get all the columns for the current table\n",
    "    get_columns_query = \"SELECT * FROM {table_name};\".format(table_name = before_table)\n",
    "    data = con.cursor().execute(get_columns_query)\n",
    "    columns = [col[0] for col in data.description]\n",
    "    \n",
    "    # Custom and formatted columns query\n",
    "    display_columns_1 = \"b.\" + columns[0] + \" AS before_date, a.\" + columns[0] + \" AS after_date, \"\n",
    "    display_columns_2 = \"a.\" + columns[0] + \" AS before_date, b.\" + columns[0] + \" AS after_Date, \"\n",
    "    for column in columns[1:-1]:\n",
    "        display_columns_1 += \"a.\" + column + \", \"\n",
    "        display_columns_2 += \"a.\" + column + \", \"\n",
    "    display_columns_2 += \"a.\" + columns[-1] + \" AS count_before, b.\" + columns[-1] + \" AS count_after\"\n",
    "    display_columns_1 += \"b.\" + columns[-1] + \" AS count_before, a.\" + columns[-1] + \" AS count_after\"\n",
    "    \n",
    "    # Join Condition query\n",
    "    join_condition = \"\"\n",
    "    for column in columns[1:-2]:\n",
    "        join_condition += \"a.\" + column + \" = b.\" + column + \" AND \"\n",
    "    join_condition += \"a.\" + columns[-2] + \" = b.\" + columns[-2]\n",
    "    \n",
    "    # Combine the queries: display + join\n",
    "    query1 = \"SELECT {display_columns} from {after_table} AS a LEFT JOIN {before_table} AS b ON {join_condition}\"\n",
    "    query1 = query1.format(display_columns = display_columns_1, after_table = after_table, before_table = before_table, join_condition = join_condition)\n",
    "    query2 = \"SELECT {display_columns} from {before_table} AS a LEFT JOIN {after_table} AS b ON {join_condition}\"\n",
    "    query2 = query2.format(display_columns = display_columns_2, before_table = before_table, after_table = after_table, join_condition = join_condition)\n",
    "    query = \"{} UNION {}\".format(query1, query2)\n",
    "    \n",
    "    # Data Cleaning\n",
    "    new_df = pd.read_sql(query, con)\n",
    "    new_df[[\"count_before\",\"count_after\"]] = new_df[[\"count_before\",\"count_after\"]].fillna(0)\n",
    "    new_df[[\"count_before\",\"count_after\"]] = new_df[[\"count_before\",\"count_after\"]].applymap(int)\n",
    "    new_df[\"Difference (after - before)\"] = new_df[\"count_after\"] - new_df[\"count_before\"]\n",
    "    # Sorting by the join condition columns\n",
    "    new_df = new_df.sort_values(new_df.columns[2:-3].tolist())\n",
    "    \n",
    "    return new_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dxf2 = DifferentialStyle(fill = PatternFill(bgColor = \"FFC7CE\"))# Red Fill\n",
    "dxf = DifferentialStyle(fill = PatternFill(bgColor = \"00CCFFCC\"))# Green Fill\n",
    "g = Rule(type = \"expression\", dxf = dxf2, stopIfTrue = True)\n",
    "r = Rule(type = \"expression\", dxf = dxf, stopIfTrue = True)\n",
    "merged_cell_font = Font(bold = True, color = \"00FFFFFF\")\n",
    "merged_cell_fill = PatternFill(\"solid\", fgColor = \"00003366\")\n",
    "merged_cell_alignment = Alignment(horizontal = \"center\", vertical = \"center\")\n",
    "\n",
    "def write_to_excel_with_formatting(df, sheet_name):\n",
    "    # Write and style the table name\n",
    "    wb = load_workbook(RESULT_FILENAME)\n",
    "    ws = wb[sheet_name]\n",
    "    current_row = ws.max_row + 2\n",
    "    table_name_cell = \"B\" + str(current_row)\n",
    "    ws[table_name_cell] = sheet_name\n",
    "    ws.merge_cells(table_name_cell + \":\" + get_column_letter(df.shape[1] + 1) + str(current_row))\n",
    "    merged_cell = ws[table_name_cell]\n",
    "    merged_cell.font = merged_cell_font\n",
    "    merged_cell.fill = merged_cell_fill\n",
    "    merged_cell.alignment = merged_cell_alignment\n",
    "    wb.save(RESULT_FILENAME)\n",
    "    \n",
    "    append_df_to_excel(filename = RESULT_FILENAME, df = df, sheet_name = sheet_name, startrow = current_row, index = True)\n",
    "    \n",
    "    # Add styling to highlight the difference\n",
    "    wb = load_workbook(RESULT_FILENAME)\n",
    "    ws = wb[sheet_name]\n",
    "    current_row += 1\n",
    "    max_row = ws.max_row\n",
    "    g.formula = ['ISBLANK($C' + str(current_row) + ')']\n",
    "    r.formula = ['ISBLANK($B' + str(current_row) + ')']\n",
    "    ws.conditional_formatting.add(\"B\" + str(current_row) + \":\" + get_column_letter(df.shape[1] + 1) + str(max_row), r)\n",
    "    ws.conditional_formatting.add(\"B\" + str(current_row) + \":\" + get_column_letter(df.shape[1] + 1) + str(max_row), g)\n",
    "    for index in range(current_row, max_row + 1):\n",
    "        ws[get_column_letter(df.shape[1] + 1) + str(index)].number_format = '#,##0'\n",
    "    ws.column_dimensions['A'].hidden = True\n",
    "    for column_cells in ws.columns: \n",
    "        unmerged_cells = list(filter(lambda cell_to_check: cell_to_check.coordinate not in ws.merged_cells, column_cells)) \n",
    "        length = max(len(str(cell.value)) for cell in unmerged_cells) \n",
    "        ws.column_dimensions[unmerged_cells[0].column_letter].width = length * 1.2\n",
    "    wb.save(RESULT_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPARISON_FILE_PATH = \"./files\"\n",
    "COMPARISON_FILE_EXTENSION = \".txt\"\n",
    "BEFORE_IMPLMENT_KEYWORD = \"Before\"\n",
    "AFTER_IMPLMENT_KEYWORD = \"After\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_data = set()\n",
    "after_data = set()\n",
    "comparison_data = list()\n",
    "\n",
    "with os.scandir(COMPARISON_FILE_PATH) as current_directory:\n",
    "    for entry in current_directory:\n",
    "        \n",
    "        # Criteria for selecting the required database\n",
    "        criteria_set = set()\n",
    "        criteria_1 = entry.name.endswith(COMPARISON_FILE_EXTENSION)\n",
    "        criteria_2 = entry.name.find(BEFORE_IMPLMENT_KEYWORD) > -1\n",
    "        criteria_3 = entry.name.find(AFTER_IMPLMENT_KEYWORD) > -1\n",
    "        criteria_set.add(criteria_1 and (criteria_2 or criteria_3))\n",
    "        \n",
    "        # Add names of the database that satisfy the criteria\n",
    "        if False not in criteria_set:\n",
    "            if criteria_2:\n",
    "                before_data.add(entry.name[ : -len(BEFORE_IMPLMENT_KEYWORD + COMPARISON_FILE_EXTENSION)])\n",
    "            else:\n",
    "                after_data.add(entry.name[ : -len(AFTER_IMPLMENT_KEYWORD + COMPARISON_FILE_EXTENSION)])\n",
    "\n",
    "# Filter out files that only has one file\n",
    "common_data = set.intersection(before_data, after_data)\n",
    "\n",
    "# Warn the user that if any files were dropped\n",
    "check_1 = set.difference(before_data, common_data)\n",
    "check_2 = set.difference(after_data, common_data)\n",
    "dropped = set.difference(check_1, check_2)\n",
    "if len(dropped) > 0:\n",
    "    print(\"WARNING: \" + str(list(dropped)) + \" was dropped since either the before or after file doesn't exist\")\n",
    "    \n",
    "comparison_data = list(common_data)\n",
    "comparison_data.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_FILENAME = \"Implementation_check_\" + str(datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")) + \".xlsx\"\n",
    "visual_df = pd.DataFrame()\n",
    "\n",
    "for db_name in comparison_data:\n",
    "    # Connection to the database\n",
    "    con = sqlite3.connect(db_name + '.db')\n",
    "    cur = con.cursor()\n",
    "    \n",
    "    # Data insertion into the database\n",
    "    insert_data_into_db(db_name, cur)\n",
    "    \n",
    "    # Get unique tables from the current database\n",
    "    query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "    cur.execute(query)\n",
    "    all_tables = [elem[0] for elem in cur.fetchall()]\n",
    "    unique_tables = set()\n",
    "    for table in all_tables:\n",
    "        suffix_index = table.rfind(\"_\")\n",
    "        unique_tables.add(table[:suffix_index])\n",
    "       \n",
    "    # Check if the both after and before version exists\n",
    "    unique_tables = list(unique_tables)\n",
    "    unique_tables.sort()\n",
    "    for table_name in unique_tables:\n",
    "        condition1 = (table_name + \"_\" + BEFORE_IMPLMENT_KEYWORD) not in all_tables\n",
    "        condition2 = (table_name + \"_\" + AFTER_IMPLMENT_KEYWORD) not in all_tables\n",
    "        if(condition1):\n",
    "            print(\"WARNING: The before information / table does not exist for table:\", table_name)\n",
    "            unique_tables.discard(table_name)\n",
    "            \n",
    "        if(condition2):\n",
    "            print(\"WARNING: The after information / table does not exist for table:\", table_name)\n",
    "            unique_tables.discard(table_name)\n",
    "    \n",
    "    if not os.path.isfile(RESULT_FILENAME):\n",
    "        wb = openpyxl.Workbook()\n",
    "        wb.save(RESULT_FILENAME)\n",
    "    wb = load_workbook(filename = RESULT_FILENAME)\n",
    "    ws = wb.create_sheet(title = db_name)\n",
    "    wb.save(RESULT_FILENAME)\n",
    "    \n",
    "    # Posting the results to excel and create graphs\n",
    "    for table_name in unique_tables:\n",
    "        result_df = create_result_df(con, table_name)\n",
    "        write_to_excel_with_formatting(result_df, db_name)\n",
    "\n",
    "    con.close()\n",
    "    os.remove(db_name + '.db')\n",
    "\n",
    "wb = load_workbook(RESULT_FILENAME)\n",
    "del wb[\"Sheet\"]\n",
    "wb.save(RESULT_FILENAME)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "220c603f019f2d62e7226453986e591ec550df177c2b48975f98b3e5f7d5e0bf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
